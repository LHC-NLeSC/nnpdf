{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cceb1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from validphys.loader import _get_nnpdf_profile\n",
    "from validphys.api import API\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from validphys.convolution import central_predictions\n",
    "\n",
    "profile = _get_nnpdf_profile()\n",
    "yaml_db = Path(profile[\"data_path\"]) / \"yamldb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1eb8f3",
   "metadata": {},
   "source": [
    "The `yaml_db` folder is a temporary thing as it contains files that look like:\n",
    "\n",
    "```yaml\n",
    "conversion_factor: 1.0\n",
    "operands:\n",
    "- - NMC_NC_EM_D_F2\n",
    "- - NMC_NC_EM_P_F2\n",
    "operation: RATIO\n",
    "target_dataset: NMCPD\n",
    "```\n",
    "\n",
    "This information will eventually be part of the new commondata format of course.\n",
    "\n",
    "The `operation` is applied to the first level of the list while the second level is just concatenated. This is necessary since `pineappl` fktables might contain one layer of concatenation which is already done for the \"classic\" fktables.\n",
    "\n",
    "The `pineappl` fktables will live inside the appropiate `theory_xxx` folder `/pineappls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051581e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.4.0 loading /usr/share/lhapdf/LHAPDF/NNPDF40_nnlo_as_01180/NNPDF40_nnlo_as_01180_0000.dat\n",
      "NNPDF40_nnlo_as_01180 PDF set, member #0, version 1\n",
      "                vp        pine ratio CMS_2JET_7TEV, ['QCD']\n",
      "                 0           0                            0\n",
      "data                                                       \n",
      "0     1.765957e+02  174.848775                     1.009991\n",
      "1     2.039113e+01   25.082712                     0.812955\n",
      "2     3.014533e+00    4.401240                     0.684928\n",
      "3     5.180528e-01    0.906572                     0.571441\n",
      "4     1.003950e-01    0.204804                     0.490201\n",
      "5     2.106041e-02    0.049915                     0.421927\n",
      "6     4.759396e-03    0.013042                     0.364939\n",
      "7     1.061027e-03    0.003342                     0.317436\n",
      "8     2.308831e-04    0.000836                     0.276226\n",
      "9     4.694783e-05    0.000194                     0.241540\n",
      "10    8.208930e-06    0.000039                     0.211423\n",
      "11    1.872755e-06    0.000007                     0.251913\n",
      "12    2.092534e-07    0.000001                     0.168370\n",
      "13    1.450895e+02  168.312338                     0.862026\n",
      "14    2.023784e+01   28.333929                     0.714262\n",
      "15    3.367332e+00    5.623462                     0.598801\n",
      "16    6.280211e-01    1.237212                     0.507610\n",
      "17    1.294898e-01    0.295244                     0.438585\n",
      "18    2.786363e-02    0.073842                     0.377343\n",
      "19    6.090526e-03    0.018516                     0.328927\n",
      "20    1.279132e-03    0.004477                     0.285700\n",
      "21    2.491170e-04    0.000999                     0.249370\n",
      "22    4.248868e-05    0.000194                     0.218822\n",
      "23    5.979919e-06    0.000031                     0.191950\n",
      "24    6.026738e-07    0.000004                     0.168359\n",
      "25    3.943581e+01   57.576491                     0.684929\n",
      "26    6.748776e+00   11.810488                     0.571422\n",
      "27    1.282157e+00    2.615640                     0.490189\n",
      "28    2.668441e-01    0.632438                     0.421929\n",
      "29    5.689477e-02    0.155900                     0.364944\n",
      "30    1.217281e-02    0.038346                     0.317444\n",
      "31    2.490435e-03    0.009016                     0.276228\n",
      "32    4.687153e-04    0.001941                     0.241542\n",
      "33    5.167645e-05    0.000311                     0.166394\n",
      "34    3.806899e-06    0.000027                     0.141453\n",
      "35    2.317486e-07    0.000002                     0.152661\n",
      "36    2.040738e+01   35.713138                     0.571425\n",
      "37    3.918010e+00    7.992846                     0.490190\n",
      "38    7.950844e-01    1.884413                     0.421927\n",
      "39    1.723086e-01    0.472149                     0.364945\n",
      "40    3.685862e-02    0.116112                     0.317441\n",
      "41    7.570107e-03    0.027405                     0.276228\n",
      "42    1.450166e-03    0.006004                     0.241542\n",
      "43    2.292070e-04    0.001084                     0.211422\n",
      "44    2.988479e-05    0.000161                     0.185542\n",
      "45    4.727042e-07    0.000007                     0.066667\n",
      "46    1.661535e+00    4.087512                     0.406491\n",
      "47    3.615961e-01    1.026984                     0.352095\n",
      "48    7.541694e-02    0.245872                     0.306732\n",
      "49    1.502379e-02    0.056341                     0.266656\n",
      "50    2.861660e-03    0.012248                     0.233643\n",
      "51    4.338305e-04    0.002117                     0.204926\n",
      "52    5.207263e-05    0.000290                     0.179546\n",
      "53    8.950783e-07    0.000012                     0.073852\n"
     ]
    }
   ],
   "source": [
    "# Test them all\n",
    "if True:\n",
    "    from yaml import safe_load\n",
    "    pdf = API.pdf(pdf=\"NNPDF40_nnlo_as_01180\")\n",
    "    all_res = []\n",
    "    nnpdf40_runcard = safe_load(Path(\"/home/juacrumar/NNPDF-testing/nnpdf/n3fit/NNPDF40_with_pineappl.yml\").read_text())\n",
    "    #nnpdf40_runcard = safe_load(Path(\"/mount/storage/Academic_Workspace/NNPDF/source/nnpdf/n3fit/NNPDF40_with_pineappl.yml\").read_text())\n",
    "    for d in nnpdf40_runcard[\"dataset_inputs\"]:\n",
    "        target_ds = d[\"dataset\"]\n",
    "        cfac = d.get(\"cfac\", [])\n",
    "        old_ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac + [\"oldmode\"]}, theoryid=200, use_cuts=\"internal\")\n",
    "        ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac}, theoryid=200, use_cuts=\"internal\")\n",
    "        new_cp = central_predictions(ds, pdf)\n",
    "        cp = central_predictions(old_ds, pdf)\n",
    "        all_res.append(pd.concat([new_cp, cp, new_cp/cp], axis=1, keys=[\"vp\", \"pine\", f\"ratio {target_ds}, {cfac}\"]))\n",
    "        \n",
    "    for i in all_res:\n",
    "        mean_ratio = i[i.columns[2]].mean()\n",
    "        if not (0.9 < mean_ratio < 1.1):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d88771",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ds = \"CMS_TTBAR_2D_DIFF_MTT_TRAP_NORM\"\n",
    "cfac = [\"QCD\"] # [\"NRM\"]\n",
    "old_ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac + [\"oldmode\"]}, theoryid=200, use_cuts=\"internal\")\n",
    "ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac}, theoryid=200, use_cuts=\"internal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316a571e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>pine</th>\n",
       "      <th>vp</th>\n",
       "      <th>ratio vp/ratio</th>\n",
       "      <th>ratio pine/vp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>1.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.992669</td>\n",
       "      <td>1.007385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.993233</td>\n",
       "      <td>1.006813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>1.001264</td>\n",
       "      <td>0.998738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.967190</td>\n",
       "      <td>1.033923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>1.003314</td>\n",
       "      <td>0.996697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>1.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.995907</td>\n",
       "      <td>1.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.960902</td>\n",
       "      <td>1.040689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>1.003073</td>\n",
       "      <td>0.996936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>1.004371</td>\n",
       "      <td>0.995648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>1.005711</td>\n",
       "      <td>0.994321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.895151</td>\n",
       "      <td>1.117130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1.000492</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.996513</td>\n",
       "      <td>1.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.006510</td>\n",
       "      <td>0.993532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pine        vp ratio vp/ratio ratio pine/vp\n",
       "             0         0              0             0\n",
       "data                                                 \n",
       "0     0.003383  0.003382       0.999938      1.000062\n",
       "1     0.003004  0.002982       0.992669      1.007385\n",
       "2     0.002128  0.002114       0.993233      1.006813\n",
       "3     0.000740  0.000741       1.001264      0.998738\n",
       "4     0.002754  0.002664       0.967190      1.033923\n",
       "5     0.002355  0.002363       1.003314      0.996697\n",
       "6     0.001637  0.001637       0.999900      1.000100\n",
       "7     0.000580  0.000578       0.995907      1.004110\n",
       "8     0.001080  0.001038       0.960902      1.040689\n",
       "9     0.000927  0.000930       1.003073      0.996936\n",
       "10    0.000675  0.000678       1.004371      0.995648\n",
       "11    0.000274  0.000276       1.005711      0.994321\n",
       "12    0.000078  0.000069       0.895151      1.117130\n",
       "13    0.000069  0.000069       1.000492      0.999508\n",
       "14    0.000064  0.000064       0.996513      1.003499\n",
       "15    0.000034  0.000035       1.006510      0.993532"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to get a prediction out of it\n",
    "pdf = API.pdf(pdf=\"NNPDF40_nnlo_as_01180\")\n",
    "new_cp = central_predictions(ds, pdf)\n",
    "cp = central_predictions(old_ds, pdf)\n",
    "pd.concat([new_cp, cp, cp/new_cp, new_cp/cp], axis=1, keys=[\"pine\", \"vp\", \"ratio vp/ratio\", \"ratio pine/vp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0905d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pine_fkspec = ds.fkspecs[0]\n",
    "old_fkspec = old_ds.fkspecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd19243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.74819495e+00 1.98846641e-01 2.90280375e-02 4.90519957e-03\n",
      " 9.44769537e-04 1.98407976e-04 4.36709986e-05 9.70543391e-06\n",
      " 2.08104072e-06 4.10372403e-07 6.98121341e-08 1.55353480e-08\n",
      " 1.66466499e-09 1.40177702e+00 1.94396456e-01 3.20542598e-02\n",
      " 5.94480545e-03 1.21760469e-03 2.58607189e-04 5.58446250e-05\n",
      " 1.15951595e-05 2.22080859e-06 3.73179113e-07 5.08574384e-08\n",
      " 5.02048228e-09 3.70769697e-01 6.25529562e-02 1.19041186e-02\n",
      " 2.43795694e-03 5.15963446e-04 1.09640302e-04 2.23113284e-05\n",
      " 4.17790750e-06 4.48599784e-07 3.19089676e-08 1.86894005e-09\n",
      " 1.84336831e-01 3.50614302e-02 7.16582800e-03 1.52306228e-03\n",
      " 3.23843890e-04 6.68743273e-05 1.24317740e-05 1.99734202e-06\n",
      " 2.53770589e-07 3.96763628e-09 1.43188858e-02 3.06196032e-03\n",
      " 6.49614036e-04 1.30079488e-04 2.35675017e-05 3.61760539e-06\n",
      " 4.21371227e-07 7.53287048e-09]\n",
      "LHAPDF 6.4.0 loading all 101 PDFs in set NNPDF40_nnlo_as_01180\n",
      "NNPDF40_nnlo_as_01180, version 1; 101 PDF members\n"
     ]
    }
   ],
   "source": [
    "import pineappl\n",
    "pines = [pineappl.fk_table.FkTable.read(i.as_posix()) for i in pine_fkspec.fkpath]\n",
    "# Inspect the pineappl prediction\n",
    "res_pine = []\n",
    "pp = pines[0]\n",
    "lpdf = pdf.load()\n",
    "\n",
    "for p in pines:\n",
    "    res_pine.append(p.convolute_with_one(2212, lpdf.central_member.xfxQ2))\n",
    "total_pine = np.concatenate(res_pine)\n",
    "print(total_pine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a77d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect the content of the old fktables, remove the cfactor for now\n",
    "from validphys.fkparser import load_fktable\n",
    "old_fkspec.cfactors = False\n",
    "old_fktabledata = load_fktable(old_fkspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab604e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hadronic?: True\n",
      "Q: 1.65\n",
      "n: 54\n",
      "xgrid shape: (50,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"hadronic?: {old_fktabledata.hadronic}\")\n",
    "print(f\"Q: {old_fktabledata.Q0}\")\n",
    "print(f\"n: {old_fktabledata.ndata}\")\n",
    "print(f\"xgrid shape: {old_fktabledata.xgrid.shape}\")\n",
    "#old_fktabledata.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62709983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First read the metadata that vp `FKTableData` needs and that all subgrids share\n",
    "Q0 = np.sqrt(pp.muf2())\n",
    "xgrid = pp.x_grid()\n",
    "# Hadronic means in practice that not all luminosity combinations are just electron X proton\n",
    "hadronic = not all(-11 in i for i in pp.lumi())\n",
    "# Now prepare the concatenation of grids\n",
    "fktables = []\n",
    "for p in pines:\n",
    "    tmp = p.table().T/p.bin_normalizations()\n",
    "    fktables.append(tmp.T)\n",
    "fktable = np.concatenate(fktables, axis=0)\n",
    "ndata = fktable.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d5a130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, 100),\n",
       " (100, 21),\n",
       " (100, 200),\n",
       " (100, 203),\n",
       " (100, 208),\n",
       " (100, 215),\n",
       " (100, 224),\n",
       " (100, 235),\n",
       " (100, 103),\n",
       " (100, 108),\n",
       " (100, 115),\n",
       " (100, 124),\n",
       " (100, 135),\n",
       " (21, 21),\n",
       " (21, 200),\n",
       " (21, 203),\n",
       " (21, 208),\n",
       " (21, 215),\n",
       " (21, 224),\n",
       " (21, 235),\n",
       " (21, 103),\n",
       " (21, 108),\n",
       " (21, 115),\n",
       " (21, 124),\n",
       " (21, 135),\n",
       " (200, 200),\n",
       " (200, 203),\n",
       " (200, 208),\n",
       " (200, 215),\n",
       " (200, 224),\n",
       " (200, 235),\n",
       " (200, 103),\n",
       " (200, 108),\n",
       " (200, 115),\n",
       " (200, 124),\n",
       " (200, 135),\n",
       " (203, 203),\n",
       " (203, 208),\n",
       " (203, 215),\n",
       " (203, 224),\n",
       " (203, 235),\n",
       " (203, 103),\n",
       " (203, 108),\n",
       " (203, 115),\n",
       " (203, 124),\n",
       " (203, 135),\n",
       " (208, 208),\n",
       " (208, 215),\n",
       " (208, 224),\n",
       " (208, 235),\n",
       " (208, 103),\n",
       " (208, 108),\n",
       " (208, 115),\n",
       " (208, 124),\n",
       " (208, 135),\n",
       " (215, 215),\n",
       " (215, 224),\n",
       " (215, 235),\n",
       " (215, 103),\n",
       " (215, 108),\n",
       " (215, 115),\n",
       " (215, 124),\n",
       " (215, 135),\n",
       " (224, 224),\n",
       " (224, 235),\n",
       " (224, 103),\n",
       " (224, 108),\n",
       " (224, 115),\n",
       " (224, 124),\n",
       " (224, 135),\n",
       " (235, 235),\n",
       " (235, 103),\n",
       " (235, 108),\n",
       " (235, 115),\n",
       " (235, 124),\n",
       " (235, 135),\n",
       " (103, 103),\n",
       " (103, 108),\n",
       " (103, 115),\n",
       " (103, 124),\n",
       " (103, 135),\n",
       " (108, 108),\n",
       " (108, 115),\n",
       " (108, 124),\n",
       " (108, 135),\n",
       " (115, 115),\n",
       " (115, 124),\n",
       " (115, 135),\n",
       " (124, 124),\n",
       " (124, 135),\n",
       " (135, 135)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.lumi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95c8549",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99782f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to join the fktable, luminosity and xgrid into a pandas dataframe\n",
    "# keeping compatibility with validphys and, hopefully, 50% of my own sanity\n",
    "\n",
    "# Step 1), make the luminosity into a 14x14 mask for the evolution basis\n",
    "eko_numbering_scheme = (22, 100, 21, 200, 203, 208, 215, 224, 235, 103, 108, 115, 124, 135)\n",
    "# note that this is the same ordering that was used in fktables\n",
    "co = []\n",
    "for i, j in pp.lumi():\n",
    "    # Ask where this would fall in a 14x14 matrix\n",
    "    idx = eko_numbering_scheme.index(i)\n",
    "    jdx = eko_numbering_scheme.index(j)\n",
    "    co.append(idx*14 + jdx)\n",
    "    \n",
    "# Step 2) prepare the indices for the dataframe\n",
    "xi = np.arange(len(xgrid))\n",
    "ni = np.arange(ndata)\n",
    "mi = pd.MultiIndex.from_product([ni, xi, xi], names=[\"data\", \"x1\", \"x2\"])\n",
    "\n",
    "# Step 3) Now play with the array until we flatten it in the right way?\n",
    "# The fktables for pineappl have this extra factor of x...\n",
    "# The output of pineappl is (ndata, flavours, x, x)\n",
    "lf = len(co)\n",
    "xfktable = fktable.reshape(ndata, lf, -1)/(xgrid[:,None]*xgrid[None,:]).flatten()\n",
    "fkmod = np.moveaxis(xfktable, 1, -1)\n",
    "fkframe = fkmod.reshape(-1, lf)\n",
    "\n",
    "# Uff, big\n",
    "df = pd.DataFrame(fkframe, index=mi, columns=co)\n",
    "\n",
    "from validphys.convolution import central_hadron_predictions\n",
    "from validphys.coredata import FKTableData\n",
    "fk = FKTableData(sigma=df, ndata=ndata,  Q0=Q0, metadata=None, hadronic=True, xgrid=xgrid)\n",
    "central_hadron_predictions(fk, pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e323f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a luminosity tensor and check that the results are correct\n",
    "from validphys.pdfbases import evolution\n",
    "\n",
    "evol_basis = (\n",
    "    \"photon\",\n",
    "    \"singlet\",\n",
    "    \"g\",\n",
    "    \"V\",\n",
    "    \"V3\",\n",
    "    \"V8\",\n",
    "    \"V15\",\n",
    "    \"V24\",\n",
    "    \"V35\",\n",
    "    \"T3\",\n",
    "    \"T8\",\n",
    "    \"T15\",\n",
    "    \"T24\",\n",
    "    \"T35\",\n",
    ")\n",
    "total_pdf = evolution.grid_values(pdf, evol_basis, xgrid, [Q0]).squeeze()[0]/xgrid\n",
    "print(total_pdf.shape)\n",
    "lumi = np.einsum('ij,kl->ikjl', total_pdf, total_pdf)\n",
    "lumi_masked = lumi[flavour_map]\n",
    "print(fktable.shape)\n",
    "print(lumi_masked.shape)\n",
    "res = np.einsum('ijkl,jkl->i', fktable, lumi_masked)\n",
    "#pd.concat([pd.DataFrame(res), cp, pd.DataFrame(res)/cp,  ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfktable.reshape(48,91,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from validphys.fkparser import open_fkpath, _parse_string, _parse_header, _build_sigma\n",
    "from validphys.fkparser import _parse_flavour_map, _parse_hadronic_fast_kernel\n",
    "try:\n",
    "    f.close()\n",
    "except:\n",
    "    pass\n",
    "f = open_fkpath(old_fkspec.fkpath)\n",
    "line_and_stream = enumerate(f, start=1)\n",
    "lineno, header = next(line_and_stream)\n",
    "res = {}\n",
    "while True:\n",
    "    marker, header_name = _parse_header(lineno, header)\n",
    "    if header_name == \"FastKernel\":\n",
    "        break\n",
    "    if header_name == \"FlavourMap\":\n",
    "        out, lineno, header = _parse_flavour_map(line_and_stream)\n",
    "    else:\n",
    "        out, lineno, header = _parse_string(line_and_stream)\n",
    "    res[header_name] = out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd41ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"FlavourMap\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_hate_pandas = _parse_hadronic_fast_kernel(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde47252",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_hate_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_fktabledata.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910dbb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devnnpdf",
   "language": "python",
   "name": "devnnpdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
